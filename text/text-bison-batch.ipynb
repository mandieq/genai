{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e192b0-e46b-49b6-b6c7-ff39c7f08633",
   "metadata": {},
   "source": [
    "# Text-bison batch prediction testing\n",
    "\n",
    "- [Documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/batch-prediction-genai)\n",
    "- [SDK docs](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextGenerationModel#vertexai_language_models_TextGenerationModel_batch_predict)\n",
    "\n",
    "Using a jsonl file located in GCS with 20 questions created using text-bison via the following prompt:\n",
    "```\n",
    "Give me 20 questions that you might ask about looking after pygmy goats. \n",
    "\n",
    "Format each question as a line in a JSONL format similar to the following example:\n",
    "{\"prompt\":\"What do they eat:\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972b74b-87dc-4b11-92c5-7a04c121ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "text_model = TextGenerationModel.from_pretrained(\"text-bison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902c2a1-1f55-4a55-87f6-2694ab5140a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"gs://BUCKET_LOCATION\"\n",
    "input_file = \"/questions.jsonl\"\n",
    "output_location = \"/results\"\n",
    "\n",
    "batch_prediction_job = text_model.batch_predict(\n",
    "  dataset=[bucket+input_file],\n",
    "  destination_uri_prefix=bucket+output_location,\n",
    "  # Optional:\n",
    "  model_parameters={\n",
    "      \"maxOutputTokens\": \"1024\",\n",
    "      \"temperature\": \"0.2\",\n",
    "      \"topP\": \"0.95\",\n",
    "      \"topK\": \"40\",\n",
    "  },\n",
    ")\n",
    "\n",
    "print(batch_prediction_job.display_name)\n",
    "print(batch_prediction_job.resource_name)\n",
    "print(batch_prediction_job.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e90ec-f8d5-4373-85f6-abd3ff893845",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5194d-7c06-4188-8dd0-15a568f6b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long did that take?\n",
    "t = batch_prediction_job.end_time - batch_prediction_job.create_time\n",
    "t.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9daa2-e1f8-4693-b8c9-e5016d346c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp -r {batch_prediction_job.output_info.gcs_output_directory} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33b80a-bb59-498c-ab8a-66559af34e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head prediction-model-*/000000000000.jsonl"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
